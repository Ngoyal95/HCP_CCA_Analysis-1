{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavior shape before (1206, 582)\n",
      "shape of restricted before (1206, 201)\n",
      "behavior shape after (460, 582)\n",
      "shape of restricted after (460, 201)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "# ***PURPOSE***\n",
    "# This script generates the vars.txt file (which is a subject x Subject Measures matrix) used by Smith et al. in their analysis of the HCP_500 data\n",
    "# See reference: https://www.fmrib.ox.ac.uk/datasets/HCP-CCA/\n",
    "\n",
    "# ***USAGE***\n",
    "# Multiple files are needed:\n",
    "# 1. a .txt file containing the names of the subject measures (SMs) to be used in the analysis\n",
    "# 2. a .txt file containing the names of all subjects to be analyzed (their subject IDs)\n",
    "# 3. the behavioral data from HCP\n",
    "# 4. the 'restricted' data from HCP (requires special access, must request this)\n",
    "# 5. the rfMRI_motion.txt file\n",
    "# 6. the quarter/release info file (named varsQconf.txt)\n",
    "\n",
    "# ***NOTE***\n",
    "# Files 1, 2, 5, and 6 are included in our GitHub repo (named subject_measure_names.txt, subject_ids.txt, rfMRI_motion.txt, and varsQconf.txt, respectively)\n",
    "\n",
    "# ***EXAMPLE USAGE ON CMD LINE***\n",
    "# ./generate_vars.py column_headers.txt subjects.txt <behavioral data> <restricted data> rfMRI_motion.txt varsQconf.txt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "cwd = os.getcwd()\n",
    "inputs = os.path.abspath(\"__file__\"+\"/../../inputs\")\n",
    "outputs = os.path.abspath(\"__file__\"+\"/../../outputs\") # NOTE CHANGE THIS TO YOUR DESIRED OUTPUT PATH!\n",
    "\n",
    "column_headers_fp = os.path.join(inputs, 'subject_measure_names.txt')\n",
    "subject_ids_fp = os.path.join(inputs, 'subject_ids.txt')\n",
    "behavioral_data_fp = os.path.join(inputs, 'unrestricted.csv')\n",
    "restricted_data_fp = os.path.join(inputs, 'restricted.csv')\n",
    "rfMRI_data_fp = os.path.join(inputs, 'rfMRI_motion.txt')\n",
    "varsQconf_fp = os.path.join(inputs, 'varsQconf.txt')\n",
    "\n",
    "# get the column headers, and names of subjects\n",
    "column_headers = [line.rstrip('\\n') for line in open(os.path.join(cwd,column_headers_fp))]\n",
    "subjects = [line.rstrip('.pconn.nii\\n') for line in open(os.path.join(cwd,subject_ids_fp))]\n",
    "\n",
    "# now import \"behavioral\" and \"restricted\" datasets into Pandas dataframes\n",
    "behavioral_data = pd.read_csv(os.path.join(cwd, behavioral_data_fp))\n",
    "restricted_data = pd.read_csv(os.path.join(cwd, restricted_data_fp))\n",
    "\n",
    "\n",
    "# Now we will filter out only the rows that correspond to the subjects specified in subjects.txt\n",
    "# Sanity check, making sure that the filtering occurs correctly\n",
    "print('behavior shape before', behavioral_data.shape)\n",
    "print('shape of restricted before', restricted_data.shape)\n",
    "\n",
    "#filter the behavioral and restricted datasets to contain only the relevant 461 subject data\n",
    "behavioral_data = behavioral_data[behavioral_data['Subject'].isin(subjects)]\n",
    "restricted_data = restricted_data[restricted_data['Subject'].isin(subjects)]\n",
    "\n",
    "print('behavior shape after', behavioral_data.shape)\n",
    "print('shape of restricted after', restricted_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the rfMRI and quarter/release (varsQconf) data\n",
    "varsqconf = pd.read_csv(varsQconf_fp, names=['quarter/release'])\n",
    "rfmri = pd.read_csv(rfMRI_data_fp, sep=\" \", names=['rfmri_motion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex so that the varsqconf has the correct subject IDs as its row labels\n",
    "varsqconf.index = rfmri.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the rfMRI and varsQconf data (we will need to do this later anyway)\n",
    "rfmri_varsqconf = pd.concat([rfmri, varsqconf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There appears to be one subject missing from the original list of 461 (for whom we have partial correlation netmats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_sub_list = list(behavioral_data['Subject'])\n",
    "restrict_sub_list = list(restricted_data['Subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['142626'], dtype='<U6')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the missing subject in each case\n",
    "np.setdiff1d(subjects,behav_sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['142626'], dtype='<U6')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(subjects,restrict_sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After investigating, subject 142626 was actually a duplicate and was removed from the ConnectomeDB\n",
    "# as a result, this analysis will need to use the subset of 460 subjects\n",
    "\n",
    "# From HCP: https://www.humanconnectome.org/study/hcp-young-adult/document/900-subjects-data-release\n",
    "# \"IMPORTANT: Subject 142626 removed from ConnectomeDB.\n",
    "# We have recently found that subject 142626, released in the 500 Subjects Release (June 2014), \n",
    "# has the same identity as another subject in the HCP study. Thus, we have removed all data for \n",
    "# subject 142626 from ConnectomeDB. For any ongoing analyses, we recommend that if possible you \n",
    "# exclude subject 142626 from your analyses.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's remove sub 142626 from our list of subjects, so that it matches the subjects in the now filtered behavioral_data and restricted_data dataframes\n",
    "subjects.remove('142626')\n",
    "\n",
    "# Also, lets drop the subject 142626 from the rfmri_varsqconf dataframe\n",
    "rfmri_varsqconf = rfmri_varsqconf.drop(index=142626)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of column headers\n",
    "behav_headers=list(behavioral_data.columns.values)\n",
    "restrict_headers=list(restricted_data.columns.values)\n",
    "\n",
    "# Make lowercase\n",
    "column_headers=[element.lower() for element in column_headers]\n",
    "behav_headers=[element.lower() for element in behav_headers]\n",
    "restrict_headers=[element.lower() for element in restrict_headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_behav = np.setdiff1d(column_headers,behav_headers)\n",
    "missing_in_restrict = np.setdiff1d(column_headers,restrict_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_in_behav_and_restrict = np.setdiff1d(missing_in_behav,restrict_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although these column headers are missing from our behavioral and restricted datasets, we will proceed to generate the vars.txt matric anyway\n",
    "# Note that in Smith et al, these empty columns were included in the matrix fed into the CCA\n",
    "# This resulted in a 461 Ã— 158 matrix S4 (which still included some missing data). These 158 SMs fed into the CCA are now listed using their formal database naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets fetch the relevant columns from each df\n",
    "\n",
    "# first, check for overlap between behavioral and restricted data\n",
    "len(np.setdiff1d(behav_headers,restrict_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like aside from the subject id, there is no overlap between columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# First, lets get the column names that are overlapped in each\n",
    "overlap_in_behav = np.intersect1d(column_headers,behav_headers)\n",
    "overlap_in_restrict = np.intersect1d(column_headers,restrict_headers)\n",
    "\n",
    "# Sanity check, confirm that the overlaps are contained by the arrays (aka check for differences)\n",
    "print(np.setdiff1d(overlap_in_behav, behav_headers))\n",
    "print(np.setdiff1d(overlap_in_restrict, restrict_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "# Okay, so we found that there is no overlaps between the column_headers and the behavior/restricted datasets which will be used to construct vars.txt\n",
    "\n",
    "# now lets do some simple math to make sure everything adds up\n",
    "total = len(overlap_in_behav) - 1 + len(overlap_in_restrict) #-1 to account for double count of 'subject'\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_headers) - total\n",
    "len(missing_in_behav_and_restrict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pull out the columns and their data\n",
    "# first we will need to convert all the column headers to lowercase\n",
    "behavioral_data.columns = behavioral_data.columns.str.lower()\n",
    "restricted_data.columns = restricted_data.columns.str.lower()\n",
    "\n",
    "behavioral_data_filtered_cols = behavioral_data[overlap_in_behav]\n",
    "restricted_data_filtered_cols = restricted_data[overlap_in_restrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 285)\n",
      "(460, 177)\n",
      "(460, 2)\n"
     ]
    }
   ],
   "source": [
    "# check that all dimensions are correct before we attempt to concat the dataframes\n",
    "print(behavioral_data_filtered_cols.shape)\n",
    "print(restricted_data_filtered_cols.shape)\n",
    "print(rfmri_varsqconf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the dataframes\n",
    "\n",
    "# first reindex all of them to match rfmri_varsqconf\n",
    "behavioral_data_filtered_cols.index = rfmri_varsqconf.index\n",
    "restricted_data_filtered_cols.index = rfmri_varsqconf.index\n",
    "\n",
    "vars = pd.concat([behavioral_data_filtered_cols, restricted_data_filtered_cols, rfmri_varsqconf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicated 'subject' column\n",
    "vars = vars.drop(columns='subject')\n",
    "vars = vars.reindex(columns = column_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output vars.txt to the 'outputs' folder\n",
    "vars.to_csv(os.path.join(outputs, \"vars.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
