{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavior shape before (1206, 582)\n",
      "shape of restricted before (1206, 201)\n",
      "behavior shape after (460, 582)\n",
      "shape of restricted after (460, 201)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "# ***PURPOSE***\n",
    "# This script generates the vars.txt file (which is a subject x Subject Measures matrix) used by Smith et al. in their analysis of the HCP_500 data\n",
    "# See reference: https://www.fmrib.ox.ac.uk/datasets/HCP-CCA/\n",
    "\n",
    "# ***USAGE***\n",
    "# Multiple files are needed:\n",
    "# 1. a .txt file containing the names of the subject measures (SMs) to be used in the analysis\n",
    "# 2. a .txt file containing the names of all subjects to be analyzed (their subject IDs)\n",
    "# 3. the behavioral data from HCP\n",
    "# 4. the 'restricted' data from HCP (requires special access, must request this)\n",
    "# 5. the rfMRI_motion.txt file\n",
    "# 6. the quarter/release info file (named varsQconf.txt)\n",
    "\n",
    "# ***NOTE***\n",
    "# Files 1, 2, 5, and 6 are included in our GitHub repo (named subject_measure_names.txt, subject_ids.txt, rfMRI_motion.txt, and varsQconf.txt, respectively)\n",
    "\n",
    "# ***EXAMPLE USAGE ON CMD LINE***\n",
    "# ./generate_vars.py column_headers.txt subjects.txt <behavioral data> <restricted data> rfMRI_motion.txt varsQconf.txt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "cwd = os.getcwd()\n",
    "inputs = os.path.abspath(\"__file__\"+\"/../../inputs\")\n",
    "outputs = os.path.abspath(\"__file__\"+\"/../../outputs\") # NOTE CHANGE THIS TO YOUR DESIRED OUTPUT PATH!\n",
    "\n",
    "column_headers_fp = os.path.join(inputs, 'subject_measure_names.txt')\n",
    "subject_ids_fp = os.path.join(inputs, 'subject_ids.txt')\n",
    "behavioral_data_fp = os.path.join(inputs, 'unrestricted.csv') #this behavioral data file is from HCP1200\n",
    "restricted_data_fp = os.path.join(inputs, 'restricted.csv') #this restricted data file is from HCP1200\n",
    "rfMRI_data_fp = os.path.join(inputs, 'rfMRI_motion.txt')\n",
    "varsQconf_fp = os.path.join(inputs, 'varsQconf.txt')\n",
    "\n",
    "# get the column headers, and names of subjects\n",
    "column_headers = [line.rstrip('\\n') for line in open(os.path.join(cwd,column_headers_fp))]\n",
    "subjects = [line.rstrip('.pconn.nii\\n') for line in open(os.path.join(cwd,subject_ids_fp))]\n",
    "\n",
    "# now import \"behavioral\" and \"restricted\" datasets into Pandas dataframes\n",
    "behavioral_data = pd.read_csv(os.path.join(cwd, behavioral_data_fp))\n",
    "restricted_data = pd.read_csv(os.path.join(cwd, restricted_data_fp))\n",
    "\n",
    "\n",
    "# Now we will filter out only the rows that correspond to the subjects specified in subjects.txt\n",
    "# Sanity check, making sure that the filtering occurs correctly\n",
    "print('behavior shape before', behavioral_data.shape)\n",
    "print('shape of restricted before', restricted_data.shape)\n",
    "\n",
    "#filter the behavioral and restricted datasets to contain only the relevant 461 subject data\n",
    "behavioral_data = behavioral_data[behavioral_data['Subject'].isin(subjects)]\n",
    "restricted_data = restricted_data[restricted_data['Subject'].isin(subjects)]\n",
    "\n",
    "print('behavior shape after', behavioral_data.shape)\n",
    "print('shape of restricted after', restricted_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the rfMRI and quarter/release (varsQconf) data\n",
    "varsqconf = pd.read_csv(varsQconf_fp, names=['quarter/release'])\n",
    "rfmri = pd.read_csv(rfMRI_data_fp, sep=\" \", names=['rfmri_motion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex so that the varsqconf has the correct subject IDs as its row labels\n",
    "varsqconf.index = rfmri.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the rfMRI and varsQconf data (we will need to do this later anyway)\n",
    "rfmri_varsqconf = pd.concat([rfmri, varsqconf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There appears to be one subject missing from the original list of 461 (for whom we have partial correlation netmats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_sub_list = list(behavioral_data['Subject'])\n",
    "restrict_sub_list = list(restricted_data['Subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['142626'], dtype='<U6')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the missing subject in each case\n",
    "np.setdiff1d(subjects,behav_sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['142626'], dtype='<U6')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(subjects,restrict_sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After investigating, subject 142626 was actually a duplicate and was removed from the ConnectomeDB\n",
    "# as a result, this analysis will need to use the subset of 460 subjects\n",
    "\n",
    "# From HCP: https://www.humanconnectome.org/study/hcp-young-adult/document/900-subjects-data-release\n",
    "# \"IMPORTANT: Subject 142626 removed from ConnectomeDB.\n",
    "# We have recently found that subject 142626, released in the 500 Subjects Release (June 2014), \n",
    "# has the same identity as another subject in the HCP study. Thus, we have removed all data for \n",
    "# subject 142626 from ConnectomeDB. For any ongoing analyses, we recommend that if possible you \n",
    "# exclude subject 142626 from your analyses.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's remove sub 142626 from our list of subjects, so that it matches the subjects in the now filtered behavioral_data and restricted_data dataframes\n",
    "subjects.remove('142626')\n",
    "\n",
    "# Also, lets drop the subject 142626 from the rfmri_varsqconf dataframe\n",
    "rfmri_varsqconf = rfmri_varsqconf.drop(index=142626)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of column headers\n",
    "behav_headers=list(behavioral_data.columns.values)\n",
    "restrict_headers=list(restricted_data.columns.values)\n",
    "\n",
    "# Make lowercase\n",
    "column_headers=[element.lower() for element in column_headers]\n",
    "behav_headers=[element.lower() for element in behav_headers]\n",
    "restrict_headers=[element.lower() for element in restrict_headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_behav = np.setdiff1d(column_headers,behav_headers)\n",
    "missing_in_restrict = np.setdiff1d(column_headers,restrict_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_in_behav_and_restrict = np.setdiff1d(missing_in_behav,restrict_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although these column headers are missing from our behavioral and restricted datasets, we will proceed to generate the vars.txt matric anyway\n",
    "# Note that in Smith et al, these empty columns were included in the matrix fed into the CCA\n",
    "# This resulted in a 461 Ã— 158 matrix S4 (which still included some missing data). These 158 SMs fed into the CCA are now listed using their formal database naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets fetch the relevant columns from each df\n",
    "\n",
    "# first, check for overlap between behavioral and restricted data\n",
    "len(np.setdiff1d(behav_headers,restrict_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like aside from the subject id, there is no overlap between columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# First, lets get the column names that are overlapped in each\n",
    "overlap_in_behav = np.intersect1d(column_headers,behav_headers)\n",
    "overlap_in_restrict = np.intersect1d(column_headers,restrict_headers)\n",
    "\n",
    "# Sanity check, confirm that the overlaps are contained by the arrays (aka check for differences)\n",
    "print(np.setdiff1d(overlap_in_behav, behav_headers))\n",
    "print(np.setdiff1d(overlap_in_restrict, restrict_headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n"
     ]
    }
   ],
   "source": [
    "# Okay, so we found that there is no overlaps between the column_headers and the behavior/restricted datasets which will be used to construct vars.txt\n",
    "\n",
    "# now lets do some simple math to make sure everything adds up\n",
    "total = len(overlap_in_behav) - 1 + len(overlap_in_restrict) #-1 to account for double count of 'subject'\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_headers) - total\n",
    "len(missing_in_behav_and_restrict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pull out the columns and their data\n",
    "# first we will need to convert all the column headers to lowercase\n",
    "behavioral_data.columns = behavioral_data.columns.str.lower()\n",
    "restricted_data.columns = restricted_data.columns.str.lower()\n",
    "\n",
    "behavioral_data_filtered_cols = behavioral_data[overlap_in_behav]\n",
    "restricted_data_filtered_cols = restricted_data[overlap_in_restrict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 284)\n",
      "(460, 176)\n",
      "(460, 2)\n"
     ]
    }
   ],
   "source": [
    "# check that all dimensions are correct before we attempt to concat the dataframes\n",
    "print(behavioral_data_filtered_cols.shape)\n",
    "print(restricted_data_filtered_cols.shape)\n",
    "print(rfmri_varsqconf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the dataframes\n",
    "\n",
    "# first reindex all of them to match rfmri_varsqconf\n",
    "behavioral_data_filtered_cols.index = rfmri_varsqconf.index\n",
    "restricted_data_filtered_cols.index = rfmri_varsqconf.index\n",
    "\n",
    "vars = pd.concat([behavioral_data_filtered_cols, restricted_data_filtered_cols, rfmri_varsqconf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>angaffect_unadj</th>\n",
       "      <th>angaggr_unadj</th>\n",
       "      <th>anghostil_unadj</th>\n",
       "      <th>cardsort_ageadj</th>\n",
       "      <th>cardsort_unadj</th>\n",
       "      <th>ddisc_auc_200</th>\n",
       "      <th>ddisc_auc_40k</th>\n",
       "      <th>ddisc_sv_10yr_200</th>\n",
       "      <th>ddisc_sv_10yr_40k</th>\n",
       "      <th>...</th>\n",
       "      <th>total_hard_liquor_7days</th>\n",
       "      <th>total_malt_liquor_7days</th>\n",
       "      <th>total_other_alc_7days</th>\n",
       "      <th>total_other_tobacco_7days</th>\n",
       "      <th>total_pipes_7days</th>\n",
       "      <th>total_snuff_7days</th>\n",
       "      <th>total_wine_7days</th>\n",
       "      <th>weight</th>\n",
       "      <th>rfmri_motion</th>\n",
       "      <th>quarter/release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100307</td>\n",
       "      <td>26-30</td>\n",
       "      <td>46.9</td>\n",
       "      <td>43.4</td>\n",
       "      <td>60.8</td>\n",
       "      <td>109.92</td>\n",
       "      <td>123.75</td>\n",
       "      <td>0.162176</td>\n",
       "      <td>0.311459</td>\n",
       "      <td>9.38</td>\n",
       "      <td>9375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.065499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100408</td>\n",
       "      <td>31-35</td>\n",
       "      <td>50.6</td>\n",
       "      <td>59.9</td>\n",
       "      <td>42.8</td>\n",
       "      <td>100.77</td>\n",
       "      <td>111.14</td>\n",
       "      <td>0.203061</td>\n",
       "      <td>0.421354</td>\n",
       "      <td>9.38</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.098191</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101006</td>\n",
       "      <td>31-35</td>\n",
       "      <td>59.0</td>\n",
       "      <td>49.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>94.30</td>\n",
       "      <td>105.19</td>\n",
       "      <td>0.283791</td>\n",
       "      <td>0.783073</td>\n",
       "      <td>40.63</td>\n",
       "      <td>28125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101107</td>\n",
       "      <td>22-25</td>\n",
       "      <td>51.9</td>\n",
       "      <td>77.2</td>\n",
       "      <td>52.3</td>\n",
       "      <td>105.69</td>\n",
       "      <td>119.76</td>\n",
       "      <td>0.088478</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>3.13</td>\n",
       "      <td>19375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.100864</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101309</td>\n",
       "      <td>26-30</td>\n",
       "      <td>38.3</td>\n",
       "      <td>54.3</td>\n",
       "      <td>36.6</td>\n",
       "      <td>86.03</td>\n",
       "      <td>99.76</td>\n",
       "      <td>0.921942</td>\n",
       "      <td>0.949740</td>\n",
       "      <td>196.88</td>\n",
       "      <td>38125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.059464</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>984472</td>\n",
       "      <td>26-30</td>\n",
       "      <td>38.1</td>\n",
       "      <td>43.4</td>\n",
       "      <td>36.6</td>\n",
       "      <td>108.28</td>\n",
       "      <td>122.17</td>\n",
       "      <td>0.164650</td>\n",
       "      <td>0.760156</td>\n",
       "      <td>3.13</td>\n",
       "      <td>20625.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.094989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>987983</td>\n",
       "      <td>26-30</td>\n",
       "      <td>46.0</td>\n",
       "      <td>56.9</td>\n",
       "      <td>53.2</td>\n",
       "      <td>100.89</td>\n",
       "      <td>115.28</td>\n",
       "      <td>0.137697</td>\n",
       "      <td>0.245703</td>\n",
       "      <td>3.13</td>\n",
       "      <td>625.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.054518</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>991267</td>\n",
       "      <td>26-30</td>\n",
       "      <td>50.6</td>\n",
       "      <td>62.1</td>\n",
       "      <td>49.1</td>\n",
       "      <td>121.37</td>\n",
       "      <td>136.10</td>\n",
       "      <td>0.172462</td>\n",
       "      <td>0.338151</td>\n",
       "      <td>9.38</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.083035</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>992774</td>\n",
       "      <td>31-35</td>\n",
       "      <td>43.8</td>\n",
       "      <td>43.4</td>\n",
       "      <td>51.5</td>\n",
       "      <td>116.01</td>\n",
       "      <td>126.37</td>\n",
       "      <td>0.017124</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>3.13</td>\n",
       "      <td>625.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.071538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>994273</td>\n",
       "      <td>26-30</td>\n",
       "      <td>50.2</td>\n",
       "      <td>65.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>101.91</td>\n",
       "      <td>112.17</td>\n",
       "      <td>0.060614</td>\n",
       "      <td>0.529427</td>\n",
       "      <td>3.13</td>\n",
       "      <td>9375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.083142</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows Ã— 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  angaffect_unadj  angaggr_unadj  anghostil_unadj  \\\n",
       "100307  26-30             46.9           43.4             60.8   \n",
       "100408  31-35             50.6           59.9             42.8   \n",
       "101006  31-35             59.0           49.8             49.0   \n",
       "101107  22-25             51.9           77.2             52.3   \n",
       "101309  26-30             38.3           54.3             36.6   \n",
       "...       ...              ...            ...              ...   \n",
       "984472  26-30             38.1           43.4             36.6   \n",
       "987983  26-30             46.0           56.9             53.2   \n",
       "991267  26-30             50.6           62.1             49.1   \n",
       "992774  31-35             43.8           43.4             51.5   \n",
       "994273  26-30             50.2           65.0             55.5   \n",
       "\n",
       "        cardsort_ageadj  cardsort_unadj  ddisc_auc_200  ddisc_auc_40k  \\\n",
       "100307           109.92          123.75       0.162176       0.311459   \n",
       "100408           100.77          111.14       0.203061       0.421354   \n",
       "101006            94.30          105.19       0.283791       0.783073   \n",
       "101107           105.69          119.76       0.088478       0.584375   \n",
       "101309            86.03           99.76       0.921942       0.949740   \n",
       "...                 ...             ...            ...            ...   \n",
       "984472           108.28          122.17       0.164650       0.760156   \n",
       "987983           100.89          115.28       0.137697       0.245703   \n",
       "991267           121.37          136.10       0.172462       0.338151   \n",
       "992774           116.01          126.37       0.017124       0.019531   \n",
       "994273           101.91          112.17       0.060614       0.529427   \n",
       "\n",
       "        ddisc_sv_10yr_200  ddisc_sv_10yr_40k  ...  total_hard_liquor_7days  \\\n",
       "100307               9.38             9375.0  ...                      0.0   \n",
       "100408               9.38             4375.0  ...                     10.0   \n",
       "101006              40.63            28125.0  ...                     10.0   \n",
       "101107               3.13            19375.0  ...                      0.0   \n",
       "101309             196.88            38125.0  ...                      0.0   \n",
       "...                   ...                ...  ...                      ...   \n",
       "984472               3.13            20625.0  ...                      3.0   \n",
       "987983               3.13              625.0  ...                      0.0   \n",
       "991267               9.38             4375.0  ...                      1.0   \n",
       "992774               3.13              625.0  ...                      3.0   \n",
       "994273               3.13             9375.0  ...                      1.0   \n",
       "\n",
       "        total_malt_liquor_7days  total_other_alc_7days  \\\n",
       "100307                      0.0                    0.0   \n",
       "100408                      0.0                    0.0   \n",
       "101006                      0.0                    0.0   \n",
       "101107                      0.0                    0.0   \n",
       "101309                      0.0                    0.0   \n",
       "...                         ...                    ...   \n",
       "984472                      0.0                    0.0   \n",
       "987983                      0.0                    0.0   \n",
       "991267                      0.0                    0.0   \n",
       "992774                      0.0                    0.0   \n",
       "994273                      0.0                    0.0   \n",
       "\n",
       "        total_other_tobacco_7days  total_pipes_7days  total_snuff_7days  \\\n",
       "100307                        0.0                0.0                0.0   \n",
       "100408                        0.0                0.0                0.0   \n",
       "101006                        0.0                0.0                0.0   \n",
       "101107                        0.0                0.0                0.0   \n",
       "101309                        0.0                0.0                0.0   \n",
       "...                           ...                ...                ...   \n",
       "984472                        0.0                0.0                0.0   \n",
       "987983                        0.0                0.0                0.0   \n",
       "991267                        1.0                0.0                0.0   \n",
       "992774                        0.0                0.0                0.0   \n",
       "994273                        0.0                0.0                0.0   \n",
       "\n",
       "        total_wine_7days  weight  rfmri_motion  quarter/release  \n",
       "100307               2.0   138.0      0.065499              0.0  \n",
       "100408               2.0   228.0      0.098191              0.0  \n",
       "101006               0.0   205.0      0.086306              1.0  \n",
       "101107               0.0   139.0      0.100864              1.0  \n",
       "101309               0.0   146.0      0.059464              1.0  \n",
       "...                  ...     ...           ...              ...  \n",
       "984472               4.0   125.0      0.094989              0.0  \n",
       "987983               0.0   136.0      0.054518              1.0  \n",
       "991267               0.0   213.0      0.083035              1.0  \n",
       "992774               0.0   138.0      0.071538              0.0  \n",
       "994273               0.0   207.0      0.083142              1.0  \n",
       "\n",
       "[460 rows x 462 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicated 'subject' column\n",
    "# vars = vars.drop(columns='subject')\n",
    "vars = vars.reindex(columns = column_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output vars.txt to the 'outputs' folder\n",
    "vars.to_csv(os.path.join(outputs, \"vars_test.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
